{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Script Case Shape - Amanda Louise Costa Nascimento"
      ],
      "metadata": {
        "id": "eP7grIEW0c17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FzqQ61Y1eA_",
        "outputId": "b4790fdb-389a-49de-f927-f67117d9913d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, from_utc_timestamp, unix_timestamp\n",
        "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, TimestampType, IntegerType\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import regexp_extract, to_timestamp\n",
        "import argparse\n",
        "import os\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, from_utc_timestamp, unix_timestamp\n",
        "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, TimestampType\n",
        "\n",
        "# Inicialize a sess√£o do Spark\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Case Shape Amanda Nascimento\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "\n",
        "# Definindo o esquema para o arquivo de equipment\n",
        "equipment_schema = StructType([\n",
        "    StructField(\"equipment_id\", IntegerType(), True),\n",
        "    StructField(\"name\", StringType(), True),\n",
        "    StructField(\"group_name\", StringType(), True)\n",
        "])\n",
        "\n",
        "# Carregando o arquivo de log\n",
        "log_df1 = spark.read.text(\"/content/equipment_failure_sensors.txt\")\n",
        "\n",
        "# Extrair informa√ß√µes usando express√µes regulares\n",
        "extracted_df = log_df1.select(\n",
        "    regexp_extract(\"value\", r\"\\[(.*?)\\]\", 1).alias(\"data_hora\"),\n",
        "    regexp_extract(\"value\", r\"sensor\\[(\\d+)\\]\", 1).alias(\"sensor_id\"),\n",
        "    regexp_extract(\"value\", r\"temperature\\s+(-?\\d+\\.\\d+)\", 1).alias(\"temp_sensor\"),\n",
        "    regexp_extract(\"value\", r\"vibration\\s+(-?\\d+\\.\\d+)\", 1).alias(\"vibration_sensor\")\n",
        ")\n",
        "# Converter a coluna 'data_hora' para o formato de timestamp\n",
        "processed_df = extracted_df.withColumn(\"data_hora\", to_timestamp(\"data_hora\", \"yyyy-MM-dd HH:mm:ss\"))\n",
        "\n",
        "# Convertendo o timestamp para UTC\n",
        "log_df = processed_df.withColumn(\"timestamp\", from_utc_timestamp(col(\"data_hora\"), \"GMT\"))\n",
        "# Renomeie a coluna sensor_id de log_df para evitar ambiguidade\n",
        "log_df = log_df.withColumnRenamed(\"sensor_id\", \"log_sensor_id\")\n",
        "\n",
        "# Carregando o arquivo de relacionamento entre sensores e equipamentos\n",
        "sensor_equipment_df1 = spark.read.csv(\"/content/equipment_sensors.csv\", header=True)\n",
        "\n",
        "# Carregando o arquivo JSON com o esquema especificado\n",
        "equipment_df = spark.read.option(\"multiline\",\"true\").schema(equipment_schema).json(\"/content/equipment.json\")\n",
        "\n",
        "# Jun√ß√£o dos dataframes para obter o nome do equipamento com base no sensor\n",
        "sensor_equipment_df = sensor_equipment_df1.join(equipment_df, sensor_equipment_df1.equipment_id == equipment_df.equipment_id, \"left\") \\\n",
        "    .select(sensor_equipment_df1[\"*\"], equipment_df[\"name\"], equipment_df[\"group_name\"])\n",
        "\n",
        "# Aplicando as consultas solicitadas\n",
        "\n",
        "# 1. Falhas totais de equipamentos que aconteceram\n",
        "total_failures = log_df.count()\n",
        "\n",
        "# 2. Nome do equipamento com mais falhas\n",
        "most_failed_equipment = log_df.join(sensor_equipment_df, log_df.log_sensor_id == sensor_equipment_df.sensor_id) \\\n",
        "    .groupBy(\"name\") \\\n",
        "    .count() \\\n",
        "    .orderBy(col(\"count\").desc()) \\\n",
        "    .select(\"name\") \\\n",
        "    .first()[0]\n",
        "\n",
        "# 3. Quantidade m√©dia de falhas em todos os grupos de equipamentos, ordenada pelo n√∫mero de falhas em ordem crescente\n",
        "average_failures_per_group = log_df.join(sensor_equipment_df, log_df.log_sensor_id == sensor_equipment_df.sensor_id) \\\n",
        "    .groupBy(\"group_name\") \\\n",
        "    .count() \\\n",
        "    .orderBy(col(\"count\").asc()) \\\n",
        "    .select(\"group_name\", (F.col(\"count\") / total_failures).alias(\"qt_media_falhas\"))\n",
        "\n",
        "# 4. Sensores que apresentam maior n√∫mero de erros por nome de equipamento em um grupo de equipamentos\n",
        "sensors_with_most_errors = log_df.join(sensor_equipment_df, log_df.log_sensor_id == sensor_equipment_df.sensor_id) \\\n",
        "    .groupBy(\"group_name\", \"name\", \"sensor_id\") \\\n",
        "    .count() \\\n",
        "    .orderBy(col(\"count\").desc()) \\\n",
        "    .select(\"group_name\", \"name\", \"sensor_id\", \"count\")\n",
        "\n",
        "# Mostrando os resultados\n",
        "print(\"1. Falhas totais de equipamentos que aconteceram:\", total_failures)\n",
        "print(\"2. Nome do equipamento com mais falhas:\", most_failed_equipment)\n",
        "print(\"3. Quantidade m√©dia de falhas em todos os grupos de equipamentos:\")\n",
        "average_failures_per_group.show()\n",
        "print(\"4. Sensores que apresentam maior n√∫mero de erros por nome de equipamento em um grupo de equipamentos:\")\n",
        "sensors_with_most_errors.show()\n",
        "\n",
        "# Encerrando a sess√£o do Spark\n",
        "#spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYXCAUtamJPm",
        "outputId": "281236e9-b3b3-41e7-c717-4dfffee31852"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Falhas totais de equipamentos que aconteceram: 77272\n",
            "2. Nome do equipamento com mais falhas: CF304D24\n",
            "3. Quantidade m√©dia de falhas em todos os grupos de equipamentos:\n",
            "+----------+-------------------+\n",
            "|group_name|    qt_media_falhas|\n",
            "+----------+-------------------+\n",
            "|  Z9K1SAP4|0.07151361424578113|\n",
            "|  NQWPA8D3|0.14107309245263486|\n",
            "|  PA92NCXZ|0.14135780101459777|\n",
            "|  9N127Z5P| 0.1423672222797391|\n",
            "|  VAPQY59S|0.21469613831659592|\n",
            "|  FGHQWR2Q| 0.2889921316906512|\n",
            "+----------+-------------------+\n",
            "\n",
            "4. Sensores que apresentam maior n√∫mero de erros por nome de equipamento em um grupo de equipamentos:\n",
            "+----------+--------+---------+-----+\n",
            "|group_name|    name|sensor_id|count|\n",
            "+----------+--------+---------+-----+\n",
            "|  NQWPA8D3|98B84035|     8001|   21|\n",
            "|  FGHQWR2Q|5310B9D7|     8917|   20|\n",
            "|  VAPQY59S|3329175B|     7169|   20|\n",
            "|  PA92NCXZ|09C37FB8|     4003|   19|\n",
            "|  FGHQWR2Q|E54B5C3A|     2826|   19|\n",
            "|  Z9K1SAP4|4E834E81|     1850|   19|\n",
            "|  VAPQY59S|2C195700|     2742|   18|\n",
            "|  FGHQWR2Q|E1AD07D4|     7725|   18|\n",
            "|  FGHQWR2Q|E54B5C3A|     3176|   18|\n",
            "|  9N127Z5P|ADE40E7F|     2476|   18|\n",
            "|  FGHQWR2Q|CF304D24|     4373|   18|\n",
            "|  FGHQWR2Q|CF304D24|      586|   18|\n",
            "|  PA92NCXZ|9AD15F7E|     6768|   18|\n",
            "|  VAPQY59S|2C195700|     9911|   18|\n",
            "|  VAPQY59S|43B81579|     9739|   18|\n",
            "|  9N127Z5P|78FFAD0C|     2157|   18|\n",
            "|  NQWPA8D3|86083278|     2011|   17|\n",
            "|  FGHQWR2Q|E1AD07D4|     8070|   17|\n",
            "|  FGHQWR2Q|5310B9D7|     6250|   17|\n",
            "|  NQWPA8D3|98B84035|     3877|   17|\n",
            "+----------+--------+---------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install black"
      ],
      "metadata": {
        "id": "VONJTlyQ4Z47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "167ee82e-0c26-4a15-94d0-0d7972e51982"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting black\n",
            "  Downloading black-24.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black) (8.1.7)\n",
            "Collecting mypy-extensions>=0.4.3 (from black)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from black) (24.0)\n",
            "Collecting pathspec>=0.9.0 (from black)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black) (4.2.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black) (4.11.0)\n",
            "Installing collected packages: pathspec, mypy-extensions, black\n",
            "Successfully installed black-24.3.0 mypy-extensions-1.0.0 pathspec-0.12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!black /content/case_shape.py"
      ],
      "metadata": {
        "id": "x-16osWz4eUL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ef6afd6-db8b-49ba-b098-bf45a8a75c32"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mreformatted /content/case_shape.py\u001b[0m\n",
            "\n",
            "\u001b[1mAll done! ‚ú® üç∞ ‚ú®\u001b[0m\n",
            "\u001b[34m\u001b[1m1 file \u001b[0m\u001b[1mreformatted\u001b[0m.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y git"
      ],
      "metadata": {
        "id": "flUIL14m4gXV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b1552c8-919d-4e87-813e-694508b00e25"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.10).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name \"amanda-louise\"\n",
        "!git config --global user.email \"amandalouise@id.uff.br\""
      ],
      "metadata": {
        "id": "jA2bTb9p5g-U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2180f277-32ce-4235-b1ea-6f6cf00f3058"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reinitialized existing Git repository in /content/.git/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git init\n",
        "!git add case_shape.py\n",
        "!git commit -m \"Adding reformatted python\"\n",
        "!git branch -M main\n",
        "!git remote add origin https://github.com/amanda-louise/case-shape.git\n",
        "!git push -u origin main"
      ],
      "metadata": {
        "id": "LhCsvc9uJ8dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "id": "CnptKmsNLcTn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}